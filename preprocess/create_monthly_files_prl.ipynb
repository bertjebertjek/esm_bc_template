{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64929a6f-1bcf-4343-99f5-7a05f5de44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "#\n",
    "#  Script to divide multi-annual netcdf files into 12 monthly files, so they can be bias corrected.\n",
    "#\n",
    "#  Modified by Bert Kruyt, original by Abby Smith, Ryan Currier(?), ...  (some original code left in comments)\n",
    "#\n",
    "#  Purpose: divide the input GCM files into 12 datasets, one for each month, with 15 days before and after as \n",
    "#           a 'buffer'. These can then be bias-corrected by month with code in github directory below.\n",
    "#\n",
    "#  Documentation: See README.md in parent dir or on github: https://github.com/bertjebertjek/esm_bc_template\n",
    "#\n",
    "#  Bert Kruyt, NCAR RAL, 2023\n",
    "#\n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf548c-f8cd-4233-ab2a-45bbca7710f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob, time, psutil\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import dask\n",
    "import time\n",
    "\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf9c5b-e133-441a-9345-68f16bca784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################     USER SETTINGS    ############################################################\n",
    "\n",
    "scenarios= ['historical', 'ssp585','ssp370']  #  ['ssp585'] #\n",
    "modLs= ['CMCC-CM2-SR5', ] # ['CESM2'] #['NorESM2-MM'] #,['NorESM2-MM'] # \n",
    "#'CanESM5','CESM2','CMCC-CM2-SR5','MIROC-ES2L','MPI-M.MPI-ESM1-2-LR','NorESM2-MM',  'CNRM-ESM2-1'\n",
    "\n",
    "\n",
    "# The raw GCM data, decompressed (!), yearly (input) :\n",
    "dir_raw_decmp = '/glade/scratch/bkruyt/CMIP6/raw/'\n",
    "\n",
    "# the directory to store the monthly files produced by this script (output):\n",
    "dir_raw_month = '/glade/scratch/bkruyt/CMIP6/raw_month/'\n",
    "\n",
    "# parallellize over the 12 months:\n",
    "Nprocs=6\n",
    "\n",
    "parallel=True\n",
    "\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93562ab-ddf6-4b46-b0f2-4b6b42f146d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\"  )\n",
    "# print(\"Creating monthly GCM files for model(s)\" , modLs, )\n",
    "# print(\" for scenario(s)\" , scenarios )\n",
    "# print(\"\\n\"  )\n",
    "\n",
    "\n",
    "def month_func(month_idx): #, ds=ds):\n",
    "    \"\"\" the function to create a monthly file from the entire dataset. To be called in parallel.\"\"\"\n",
    "\n",
    "    print(\"\\n    ----- month \", month_idx, \"------\")\n",
    "\n",
    "    month_grouped=ds['time'].dt.month\n",
    "    month_grouped[month_grouped!=month_idx]=0   # if not the current month, set to zero\n",
    "    idx=np.where(np.diff(month_grouped.values)!=0)[0]  # the (time) indices where the month changes\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        # print(i)\n",
    "        month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "        if i==0 and month_idx==1:\n",
    "            month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "        elif i == len(idx)-1 and month_idx==12:\n",
    "            print('executed')\n",
    "            month_grouped=month_grouped # leave as is: dont go forward\n",
    "        elif i < len(idx)-1:\n",
    "            try:  # originally whole try statement was commented out\n",
    "                # month_grouped[ idx[i+1]+1 : idx[i+1]+16 ] = month_idx*np.ones(15)  # org\n",
    "                month_grouped[ idx[i+1]+1 : idx[i+1]+(15*4)+1 ] = month_idx*np.ones(15*4)  # BK addition\n",
    "            except:\n",
    "                month_grouped=month_grouped\n",
    "            # month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)  # original code. \n",
    "\n",
    "            print('   grouping')\n",
    "            t2=time.time()\n",
    "            # dsGroup=ds.groupby(month_grouped).groups\n",
    "            # print('   grouped ', round(time.time()-t2,2) ); t3=time.time()\n",
    "            # ds_month=ds.isel(time=dsGroup[month_idx]).load() \n",
    "            # print( '   ds_month loaded ' , round(time.time()-t3,2) )\n",
    "            \n",
    "            # this may be way faster?\n",
    "            ds_month = ds.sel(time=ds.time[month_grouped.values.astype('bool')]) #.load() add this next time round\n",
    "            print('   grouped ', round(time.time()-t2,2) ); t3=time.time()\n",
    "            # - - - - - - - - - -- - - - - -\n",
    "\n",
    "            # validate:\n",
    "            try:\n",
    "                print(\"   \", ds_month.time.values[0].astype('datetime64[D]') ,  ds_month.time.values[-1].astype('datetime64[D]') )\n",
    "            except: # if calendar is noleap the above will fail and we use:\n",
    "                print('   ', ds_month.time.dt.calendar )\n",
    "                print(\"   \", ds_month.indexes['time'].to_datetimeindex().values.min().astype('datetime64[D]'), \n",
    "                             ds_month.indexes['time'].to_datetimeindex().values.max().astype('datetime64[D]'))\n",
    "                # ds_month['time'] = ds_month.indexes['time'].to_datetimeindex()\n",
    "\n",
    "\n",
    "            # print mem usage:\n",
    "            # Getting % usage of virtual_memory ( 3rd field) !!! This gives % of Node, not of mem allocated, so better use absolute amount below:\n",
    "            # print('   * * *   RAM memory % used:', psutil.virtual_memory()[2], '   * * *   ')\n",
    "            # Getting usage of virtual_memory in GB ( 4th field)\n",
    "            print('   * * *   RAM Used (GB):', psutil.virtual_memory()[3]/1000000000, '   * * *   \\n')\n",
    "\n",
    "            # save the monthly file to disk:\n",
    "            # !!! Note that the esm_bias_correction fortran code expects this time encoding, if it is changed here the output of the bias correction will have the wromg time stamp!!!!\n",
    "\n",
    "            print('   writing to disk' ); t4=time.time()\n",
    "            ds_month.to_netcdf(out_dir+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc'  ,  encoding={'time':{'units':\"days since 1900-01-01\"}}) \n",
    "\n",
    "            print( '   saved month',month_idx,' to ', out_dir+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc', '   took ',  round(time.time()-t4,2) )\n",
    "\n",
    "            del ds_month\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480789d2-8355-49c1-bf77-a4af5838f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#-------------------- loop over months and scenarios  ------------------\n",
    "for z in range(len(modLs)):\n",
    "    t0 = time.time()\n",
    "    for scen in scenarios:\n",
    "        print(modLs[z], scen)\n",
    "        t1 = time.time()\n",
    "\n",
    "        # Open the entire raw dataset for this scenatio:\n",
    "        \n",
    "        if modLs[z] =='CMCC-CM2-SR5':\n",
    "            ds = xr.open_mfdataset( dir_raw_decmp + modLs[z]+'/'+scen+'/'+'*_6hrLev_'+scen+'_*_subset_c.nc'  ,combine='by_coords', chunks = {'time':10} )\n",
    "            print(  dir_raw_decmp + modLs[z]+'/'+scen+'/'+'*_6hrLev_'+scen+'_*_subset_c.nc' )\n",
    "        else:\n",
    "            ds = xr.open_mfdataset( dir_raw_decmp + modLs[z]+'/'+scen+'/'+modLs[z]+'_6hrLev_'+scen+'_*_subset_c.nc'  ,combine='by_coords', chunks = {'time':10} )\n",
    "            print(dir_raw_decmp + modLs[z]+'/'+scen+'/'+modLs[z]+'_6hrLev_'+scen+'_*_subset_c.nc') # for debugging\n",
    "            \n",
    "        # for testing, open just one file (look at years/scen combi)  # NB YEAR!!\n",
    "        # ds = xr.open_mfdataset( dir_raw_decmp + modLs[z]+'/'+scen+'/'+modLs[z]+'_6hrLev_'+scen+'_*_20150101-20200101_subset_c.nc'  ,combine='by_coords') # 1 file of 5y for testing \n",
    "        # ds = xr.open_mfdataset( dir_raw_decmp + modLs[z]+'/'+scen+'/'+modLs[z]+'_6hrLev_'+scen+'_*_19500101-19600101_subset_c.nc'  ,combine='by_coords') # 1 file of 5y for testing \n",
    "\n",
    "\n",
    "        ds=ds.sel(time=slice('1950-01-01T12:00','2099-12-31T18:00'))\n",
    "        ds=ds.sel(time=~ds.get_index(\"time\").duplicated())\n",
    "        ds['P'] = ds['P'].astype('float32')\n",
    "        ds['SST'] = ds['SST'].astype('float32')\n",
    "\n",
    "        gcmP   = ds['P']\n",
    "        gcmPs  = ds['Ps']\n",
    "        gcmT   = ds['T']\n",
    "        gcmHGT = ds['HGT']\n",
    "\n",
    "        g  = 9.80665\n",
    "        R  = 8.3144598\n",
    "        M  = 0.0289644\n",
    "        Lb = -6.5/1000 #(K/m)\n",
    "\n",
    "        exponent = ((-g*M)/(R*Lb))\n",
    "        P_ratio  = gcmP/gcmPs\n",
    "        T_b      = gcmT[:,0,:,:]\n",
    "        ds['Z']  = (((T_b*np.exp((np.log(P_ratio)/exponent))))-T_b)/Lb\n",
    "        ds['Z']  = ds['Z']+gcmHGT\n",
    "        ds['Z']  = ds['Z'].transpose(\"time\", \"lev\", \"lat\", \"lon\")\n",
    "        print('computed Z for '+modLs[z])\n",
    "\n",
    "        # make output directory (w. modLs[z]/scen subdirs) if it doesnt exist:\n",
    "        out_dir = dir_raw_month + modLs[z] +'/' + scen + '/'\n",
    "        if not os.path.exists(out_dir):\n",
    "            # os.mkdir(out_dir)\n",
    "            os.makedirs(out_dir)  # to make parent + subdirs\n",
    "\n",
    "        if parallel:\n",
    "            ## Call in parallel :\n",
    "            with mp.Pool(processes = Nprocs) as p:\n",
    "                p.map( month_func, range(1,13) )          # for month_idx in range(1,13):\n",
    "\n",
    "        else:   #  -----------  serial ------------\n",
    "\n",
    "            for month_idx in range(1,13):    \n",
    "                print(\"\\n    ----- month \", month_idx, \"------\")            \n",
    "\n",
    "                month_grouped=ds['time'].dt.month\n",
    "                month_grouped[month_grouped!=month_idx]=0   # if not the current month, set to zero\n",
    "                idx=np.where(np.diff(month_grouped.values)!=0)[0]  # the (time) indices where the month changes\n",
    "\n",
    "                for i in range(len(idx)):\n",
    "                    # print(i)\n",
    "                    month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "                    if i==0 and month_idx==1:\n",
    "                        month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "                    elif i == len(idx)-1 and month_idx==12:\n",
    "                        print('executed')\n",
    "                        month_grouped=month_grouped # leave as is: dont go forward\n",
    "                    elif i < len(idx)-1:\n",
    "                        # try:  # originally whole try statement was commented out\n",
    "                        #     # month_grouped[ idx[i+1]+1 : idx[i+1]+16 ] = month_idx*np.ones(15)  # org\n",
    "                        #     month_grouped[ idx[i+1]+1 : idx[i+1]+(15*4)+1 ] = month_idx*np.ones(15*4)  # BK addition\n",
    "                        # except:\n",
    "                        #     month_grouped=month_grouped\n",
    "                        month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)  # original code. \n",
    "\n",
    "                print('   grouping')\n",
    "                t2=time.time()\n",
    "                # dsGroup=ds.groupby(month_grouped).groups\n",
    "                # print('   grouped ', round(time.time()-t2,2) ); t3=time.time()\n",
    "                # ds_month=ds.isel(time=dsGroup[month_idx]).load() \n",
    "                # print( '   ds_month loaded ' , round(time.time()-t3,2) )\n",
    "\n",
    "                # this may be way faster?\n",
    "                ds_month = ds.sel(time=ds.time[month_grouped.values.astype('bool')]) #.load() add this next time round\n",
    "                print('   grouped ', round(time.time()-t2,2) ); t3=time.time()\n",
    "                # - - - - - - - - - -- - - - - -\n",
    "\n",
    "                # validate:\n",
    "                try:\n",
    "                    print(\"   \", ds_month.time.values[0].astype('datetime64[D]') ,  ds_month.time.values[-1].astype('datetime64[D]') )\n",
    "                except: # if calendar is noleap the above will fail and we use:\n",
    "                    print('   ', ds_month.time.dt.calendar )\n",
    "                    print(\"   \", ds_month.indexes['time'].to_datetimeindex().values.min().astype('datetime64[D]'), \n",
    "                                 ds_month.indexes['time'].to_datetimeindex().values.max().astype('datetime64[D]'))\n",
    "                    # ds_month['time'] = ds_month.indexes['time'].to_datetimeindex()\n",
    "                    \n",
    "                # print the nr of times a certain month is in the month's file:\n",
    "                if month_idx==1 and np.any(ds_month.time.dt.month==12): \n",
    "                    print('   month ',12,' ',sum(ds_month.time.dt.month.values==12),'times in month ',month_idx)\n",
    "                elif np.any(ds_month.time.dt.month==month_idx-1): \n",
    "                    print('   month ',month_idx-1,' ',sum(ds_month.time.dt.month.values==month_idx-1), 'times in month ',month_idx)\n",
    "\n",
    "                if np.any(ds_month.time.dt.month==month_idx): \n",
    "                    print('   month ',month_idx,' ',sum(ds_month.time.dt.month.values==month_idx),' times in month ',month_idx)\n",
    "\n",
    "                if month_idx!=12 and np.any(ds_month.time.dt.month==month_idx+1): \n",
    "                    print('   month ',month_idx+1,' ',sum(ds_month.time.dt.month.values==month_idx+1),' times in month ',month_idx)\n",
    "                elif month_idx==12 and np.any(ds_month.time.dt.month==1): \n",
    "                    print('   month ',1,' ',sum(ds_month.time.dt.month.values==1),' times in month ',month_idx\n",
    "\n",
    "\n",
    "                # print mem usage:\n",
    "                # Getting % usage of virtual_memory ( 3rd field) !!! This gives % of Node, not of mem allocated, so better use absolute amount below:\n",
    "                # print('   * * *   RAM memory % used:', psutil.virtual_memory()[2], '   * * *   ')\n",
    "                # Getting usage of virtual_memory in GB ( 4th field)\n",
    "                print('   * * *   RAM Used (GB):', psutil.virtual_memory()[3]/1000000000, '   * * *   \\n')\n",
    "\n",
    "                # save the monthly file to disk:\n",
    "                # !!! Note that the esm_bias_correction fortran code expects this time encoding, if it is changed here the output of the bias correction will have the wromg time stamp!!!!\n",
    "\n",
    "                print('   writing to disk . . .' ); t4=time.time()\n",
    "                ds_month.to_netcdf(out_dir+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc'  ,  encoding={'time':{'units':\"days since 1900-01-01\"}}) \n",
    "\n",
    "                print( '   saved month',month_idx,' to ', out_dir+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc', ' in ',  round(time.time()-t4,2), 's' )\n",
    "\n",
    "                del ds_month #??\n",
    "\n",
    "        \n",
    "        \n",
    "        print(modLs[z], scen, \" time: \", time.time() - t1 ) \n",
    "    print(modLs[z], \" tot time: \", time.time() - t0 ) \n",
    "\n",
    "# print(\"\\n\")\n",
    "# print(\"************************  Finished creating monthly files **************************\")\n",
    "# print(\"*********        For models: \", modLs, \"        ************\")\n",
    "# print(\"*********        and scenarios: \", scenarios, \"         ************\")\n",
    "# print(\"************************************************************************************* \")\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28d726-4a13-4789-8caa-8c8b08e7bbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44987359-3fd4-4a4e-b246-9a346abd81a7",
   "metadata": {},
   "source": [
    "## alternative grouping method (faster?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841cf9b-bc6f-474e-9007-48a9a2d97060",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(idx)):\n",
    "    print(i, len(idx))\n",
    "    month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "    if i==0 and month_idx==1:\n",
    "        month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "    elif i == len(idx)-1 and month_idx==12:\n",
    "        print('executed')\n",
    "        month_grouped=month_grouped # leave as is: dont go forward\n",
    "    elif i < len(idx)-1:\n",
    "        try:  # originally whole try statement was commented out\n",
    "            # month_grouped[ idx[i+1]+1 : idx[i+1]+16 ] = month_idx*np.ones(15)  # org\n",
    "            month_grouped[ idx[i+1]+1 : idx[i+1]+(15*4)+1 ] = month_idx*np.ones(15*4)  # BK addition\n",
    "        except:\n",
    "            month_grouped=month_grouped\n",
    "        # month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)  # original code. \n",
    "\n",
    "    print('grouping'); \n",
    "    dsGroup=ds.groupby(month_grouped).groups\n",
    "    ds_month=ds.isel(time=dsGroup[month_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ed787-658c-460d-80eb-1c84ee8d8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_grouped.values\n",
    "ds_month_2 = ds.sel(time=ds.time[month_grouped.values.astype('bool')])\n",
    "# tst = ds.time[month_grouped.values]\n",
    "# tst\n",
    "print(len(ds.time.values),  len(ds_month_2.time.values), \n",
    "      ds.time.values.min(),  ds_month_2.time.values.min(),\n",
    "    ds.time.values.max(),  ds_month_2.time.values.max()\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f59b6-8961-4bcf-ae30-5ad43e71fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mon in range(1,13):\n",
    "    print( mon in ds_month_2.time.dt.month ,  mon in ds_month.time.dt.month ,     mon in ds.time.dt.month )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy39",
   "language": "python",
   "name": "mypy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

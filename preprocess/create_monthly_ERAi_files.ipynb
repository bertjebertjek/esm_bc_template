{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcfaee7-baea-4cd9-a8cb-5f83a0bbd0c1",
   "metadata": {},
   "source": [
    "# Erai monthly preprocessing\n",
    "\n",
    "Aggregate the ERA interim data into 12 monthly files, with all years for each month (+/- 15 days of buffer)\n",
    "\n",
    "based on code from Ryan currier:\n",
    "/glade/u/home/currierw/make_monthly_erai_dataset.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02a8bfb-8be0-48fe-899f-fe55c6b0bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55edf37-3b95-494c-afd6-d3e5cf74b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_in='/glade/u/home/currierw/scratch/erai/convection/erai/'\n",
    "# path_out='/glade/u/home/currierw/scratch/erai/convection/erai/clipped_by_month_convert_SST/'\n",
    "\n",
    "path_in='/glade/scratch/gutmann/icar/forcing/erai_conus/monthly'  # path with erai files (chronological)\n",
    "path_out='/glade/scratch/bkruyt/erai/erai_greatlakes_month/' # path where 12 monthly files will be written\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086c0b48-152e-4697-8182-e59df5ca89b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-95.161194 -70.338806 39.514442 50.168922\n"
     ]
    }
   ],
   "source": [
    "# load a wps file to crop the ERA data to:\n",
    "GEO=xr.open_dataset('/glade/work/bkruyt/WPS/ICAR_domains/great_lakes_6km/geo_em.d01.nc') \n",
    "# plt.pcolormesh(GEO.XLONG_M.isel(Time=0), GEO.XLAT_M.isel(Time=0), GEO.HGT_M.isel(Time=0) )\n",
    "print( GEO.XLONG_M.values.min(), GEO.XLONG_M.values.max(), GEO.XLAT_M.values.min(), GEO.XLAT_M.values.max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c8c5d-df7f-4e99-81ac-f463706a4e96",
   "metadata": {},
   "source": [
    "## Load orginals and crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a2167c-f043-42c5-b435-9ed904068489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.514442443847656, 51.168922424316406] [-96.16119384765625, -69.33880615234375]\n",
      "38.94728 50.87706 -95.62491 -69.60928\n",
      "CPU times: user 3min 37s, sys: 7min 1s, total: 10min 39s\n",
      "Wall time: 32min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load all files at once:\n",
    "files=sorted(glob.glob(path_in+'/erai-*.nc'))\n",
    "dsERAi=xr.open_mfdataset(files,combine='by_coords') \n",
    "\n",
    "#  Crop (optionally)\n",
    "# lat_bnds, lon_bnds = [25, 56], [-130, -96] # W-Conus\n",
    "\n",
    "# Crop to Great Lakes domain (+0.5 deg)\n",
    "buff=1.0 #0.5\n",
    "lat_bnds = [ (GEO.XLAT_M.values.min()-buff), (GEO.XLAT_M.values.max() +buff)] \n",
    "lon_bnds = [ (GEO.XLONG_M.values.min()-buff), (GEO.XLONG_M.values.max()+buff)]\n",
    "print(lat_bnds, lon_bnds)\n",
    "\n",
    "# crop and load to memory(?) - Be mindful about memory, uncropped this is ~750 GB\n",
    "dsERAi_clip=dsERAi.sel(lat=slice(*lat_bnds),lon=slice(*lon_bnds)).load()\n",
    "\n",
    "print( dsERAi_clip.lat.values.min(), dsERAi_clip.lat.values.max(),  \n",
    "      dsERAi_clip.lon.values.min(), dsERAi_clip.lon.values.max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d0312-d2ac-47af-86ab-00bcbc663758",
   "metadata": {},
   "source": [
    "### Calculate water vapor mixing ratio, air temperature, and convective precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e550259-80b7-4d14-bd91-750ba5d446a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify parameters:\n",
    "\n",
    "dsERAi_clip['qv']=(dsERAi_clip['qv']/(1-dsERAi_clip['qv']))\n",
    "dsERAi_clip['qv']=dsERAi_clip['qv'].assign_attrs({'long_name': 'Water Vapor Mixing Ratio', 'units': 'kg kg**-1'})\n",
    "\n",
    "# somehow this introduces a few NaN's, although there aren't any in theta or p. \n",
    "dsERAi_clip['T'] = dsERAi_clip['theta']*((dsERAi_clip['p']/100000)**(2/7))\n",
    "dsERAi_clip['T']=dsERAi_clip['T'].assign_attrs({'long_name': 'Air Temperature', 'units': 'K'})\n",
    "\n",
    "dsERAi_clip['cp']=dsERAi_clip['cp']/21600\n",
    "dsERAi_clip['cp']=dsERAi_clip['cp'].assign_attrs({'long_name': 'Convective Precipitation', 'units': 'mm/s','Note':'Converted from mm/time step (6 hours) to mm/s by dividing by 21600'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79583397",
   "metadata": {},
   "source": [
    "### Remove NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vrs=['theta','T']\n",
    "# for var in vrs:\n",
    "#     nan_idx = np.isnan(dsERAi_clip[var].values)\n",
    "#     nan_idx+=nan_idx\n",
    "\n",
    "# nan_indices=nan_idx.astype(bool)\n",
    "# print('NaNs found at times ', dsERAi_clip.time[nan_indices[:,0,0,0]].values ,\"\\n\")\n",
    "\n",
    "# dsERAi_clip = dsERAi_clip.sel(time=~nan_indices[:,0,0,0])  \n",
    "\n",
    "## Better to interpolate so time stays continuous:\n",
    "dsERAi_clip['T']=dsERAi_clip['T'].interpolate_na(dim='time')\n",
    "dsERAi_clip['theta']=dsERAi_clip['theta'].interpolate_na(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec87052-338a-4833-ae31-f83acd141bcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create monthly files (serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610ffb5f-a3af-46d4-89f6-cc467e5457e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1979-01-01 2019-02-15\n",
      "   * * *   RAM Used (GB): 187.265990656    * * *   \n",
      "\n",
      "month 1 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--01.nc\n",
      "    1979-01-17 2019-03-15\n",
      "   * * *   RAM Used (GB): 186.612678656    * * *   \n",
      "\n",
      "month 2 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--02.nc\n",
      "    1979-02-14 2019-04-15\n",
      "   * * *   RAM Used (GB): 187.385483264    * * *   \n",
      "\n",
      "month 3 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--03.nc\n",
      "    1979-03-17 2019-05-15\n",
      "   * * *   RAM Used (GB): 187.099099136    * * *   \n",
      "\n",
      "month 4 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--04.nc\n",
      "    1979-04-16 2019-06-15\n",
      "   * * *   RAM Used (GB): 187.669413888    * * *   \n",
      "\n",
      "month 5 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--05.nc\n",
      "    1979-05-17 2019-07-15\n",
      "   * * *   RAM Used (GB): 187.0998528    * * *   \n",
      "\n",
      "month 6 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--06.nc\n",
      "    1979-06-16 2019-08-15\n",
      "   * * *   RAM Used (GB): 187.675348992    * * *   \n",
      "\n",
      "month 7 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--07.nc\n",
      "    1979-07-17 2019-08-31\n",
      "   * * *   RAM Used (GB): 187.570507776    * * *   \n",
      "\n",
      "month 8 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--08.nc\n",
      "    1979-08-17 2018-10-15\n",
      "   * * *   RAM Used (GB): 186.96470528    * * *   \n",
      "\n",
      "month 9 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--09.nc\n",
      "    1979-09-16 2018-11-15\n",
      "   * * *   RAM Used (GB): 187.23395584    * * *   \n",
      "\n",
      "month 10 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--10.nc\n",
      "    1979-10-17 2018-12-15\n",
      "   * * *   RAM Used (GB): 186.993770496    * * *   \n",
      "\n",
      "month 11 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--11.nc\n",
      "executed\n",
      "    1979-11-16 2019-01-15\n",
      "   * * *   RAM Used (GB): 186.887688192    * * *   \n",
      "\n",
      "month 12 saved to /glade/scratch/bkruyt/erai/erai_conus_bymonth/erai--12.nc\n"
     ]
    }
   ],
   "source": [
    "for month_idx in range(1,13):\n",
    "\n",
    "    # month_idx=month\n",
    "    month_grouped=dsERAi_clip['time'].dt.month\n",
    "    month_grouped[month_grouped!=month_idx]=0 # set month to zero for all but the current month\n",
    "    idx=np.where(np.diff(month_grouped.values)!=0)[0] # the time-indices where the month changes\n",
    "    \n",
    "    for i in range(len(idx)):\n",
    "        # print(i)\n",
    "        month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "        if i==0 and month_idx==1:\n",
    "            month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "        elif i == len(idx)-1 and month_idx==12:\n",
    "            print('executed')\n",
    "            month_grouped=month_grouped # leave as is: dont go forward\n",
    "        elif i < len(idx)-1:\n",
    "            try:  # originally whole try statement was commented out\n",
    "            #     # month_grouped[ idx[i+1]+1 : idx[i+1]+16 ] = month_idx*np.ones(15)  # org\n",
    "            #     month_grouped[ idx[i+1]+1 : idx[i+1]+(15*4)+1 ] = month_idx*np.ones(15*4)  # BK addition\n",
    "            # except:\n",
    "            #     month_grouped=month_grouped                  \n",
    "            month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)  # original code. \n",
    "\n",
    "    dsGroup=dsERAi_clip.groupby(month_grouped).groups\n",
    "    ds_month=dsERAi_clip.isel(time=dsGroup[month_idx])\n",
    "\n",
    "\n",
    "    # validate:\n",
    "    try:\n",
    "        print(\"   \", ds_month.time.values[0].astype('datetime64[D]') ,  ds_month.time.values[-1].astype('datetime64[D]') )\n",
    "    except: # if calendar is noleap the above will fail and we use:\n",
    "        print(\"   \", ds_month.indexes['time'].to_datetimeindex().values.min().astype('datetime64[D]'), \n",
    "                     ds_month.indexes['time'].to_datetimeindex().values.max().astype('datetime64[D]'))\n",
    "\n",
    "    # Check if +/ 15 day buffer worked out:\n",
    "    if month_idx==1 and np.any(ds_month.time.dt.month==12): \n",
    "        print('   month ',12,' ',sum(ds_month.time.dt.month.values==12),'times in ',month_idx)\n",
    "    elif np.any(ds_month.time.dt.month==month_idx-1): \n",
    "        print('   month ',month_idx-1,' ',sum(ds_month.time.dt.month.values==month_idx-1), 'times in ',month_idx)\n",
    "\n",
    "    if np.any(ds_month.time.dt.month==month_idx): \n",
    "        print('   month ',month_idx,' in ',month_idx)\n",
    "\n",
    "    if month_idx!=12 and np.any(ds_month.time.dt.month==month_idx+1): \n",
    "        print('   month ',month_idx+1,' ',sum(ds_month.time.dt.month.values==month_idx+1),' times in ',month_idx)\n",
    "    elif month_idx==12 and np.any(ds_month.time.dt.month==1): \n",
    "        print('   month ',1,' ',sum(ds_month.time.dt.month.values==1),'times in ',month_idx)\n",
    "        \n",
    "    # check if NaN;s are really gone:\n",
    "    for var in ['T','theta']:\n",
    "        print( '   nans in ' +var+': ' + str(np.isnan( ds_month[var].values).sum()) )\n",
    "    # print mem usage:\n",
    "    # Getting % usage of virtual_memory ( 3rd field) !!! This gives % of Node, not of mem allocated, so better use absolute amount below:\n",
    "    # print('   * * *   RAM memory % used:', psutil.virtual_memory()[2], '   * * *   ')\n",
    "    # Getting usage of virtual_memory in GB ( 4th field)\n",
    "    print('   * * *   RAM Used (GB):', psutil.virtual_memory()[3]/1000000000, '   * * *   ')\n",
    "\n",
    "    # save to 1 file per month:\n",
    "    ds_month.to_netcdf(path_out+ 'erai_'+str(month_idx).zfill(2)+'.nc',  \n",
    "                       encoding={'time':{'units': \"days since 1900-01-01 00:00:00\"}}) # rerun for encoding....\n",
    "    print('month '+str(month_idx)+\" saved to \" +path_out+ 'erai_'+str(month_idx).zfill(2)+'.nc' +' \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5226d7-42b7-4e1b-a495-02b2061188ae",
   "metadata": {},
   "source": [
    "### Create monthly files (parallel)\n",
    "\n",
    "Same function as before, but in parallel. If the dsERAi_clip dataset can be loaded (.load()) into memory, this parallel processing is not really needed. Kept here for whoever wants to play with it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfc6ae6-118d-41f0-8e81-903191edfadb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import psutil\n",
    "\n",
    "# from create_monthly_files_prl:\n",
    "def month_func(month_idx, ds=dsERAi_clip): \n",
    "    \"\"\" the function to create a monthly file from the entire dataset. To be called in parallel.\"\"\"\n",
    "\n",
    "    print(\"\\n    ----- month \", month_idx, \"------\")\n",
    "\n",
    "    month_grouped=ds['time'].dt.month\n",
    "    month_grouped[month_grouped!=month_idx]=0   # if not the current month, set to zero\n",
    "    idx=np.where(np.diff(month_grouped.values)!=0)[0]  # the (time) indices where the month changes\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        # print(i)\n",
    "        month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "        if i==0 and month_idx==1:\n",
    "            month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "        elif i == len(idx)-1 and month_idx==12:\n",
    "            print('executed')\n",
    "            month_grouped=month_grouped # leave as is: dont go forward\n",
    "        elif i < len(idx)-1:\n",
    "            # try:  # originally whole try statement was commented out\n",
    "            #     # month_grouped[ idx[i+1]+1 : idx[i+1]+16 ] = month_idx*np.ones(15)  # org\n",
    "            #     month_grouped[ idx[i+1]+1 : idx[i+1]+(15*4)+1 ] = month_idx*np.ones(15*4)  # BK addition\n",
    "            # except:\n",
    "            #     month_grouped=month_grouped                  \n",
    "            month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)  # original code. \n",
    "\n",
    "    dsGroup=ds.groupby(month_grouped).groups\n",
    "    ds_month=ds.isel(time=dsGroup[month_idx])\n",
    "\n",
    "    # validate:\n",
    "    try:\n",
    "        print(\"   \", ds_month.time.values[0].astype('datetime64[D]') ,  ds_month.time.values[-1].astype('datetime64[D]') )\n",
    "    except: # if calendar is noleap the above will fail and we use:\n",
    "        print(\"   \", ds_month.indexes['time'].to_datetimeindex().values.min().astype('datetime64[D]'), \n",
    "                     ds_month.indexes['time'].to_datetimeindex().values.max().astype('datetime64[D]'))\n",
    "\n",
    "    # print mem usage:\n",
    "    # Getting % usage of virtual_memory ( 3rd field) !!! This gives % of Node, not of mem allocated, so better use absolute amount below:\n",
    "    # print('   * * *   RAM memory % used:', psutil.virtual_memory()[2], '   * * *   ')\n",
    "    # Getting usage of virtual_memory in GB ( 4th field)\n",
    "    print('   * * *   RAM Used (GB):', psutil.virtual_memory()[3]/1000000000, '   * * *   \\n')\n",
    "\n",
    "    # save the monthly file to disk:\n",
    "    # ds_month.to_netcdf(out_dir+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc'  ,  encoding={'time':{'units': \"days since 1900-01-01 00:00:00\"}}) \n",
    "    \n",
    "    ds_month.to_netcdf(path_out+ 'erai_'+str(month_idx).zfill(2)+'.nc',  \n",
    "                       encoding={'time':{'units': \"days since 1900-01-01 00:00:00\"}}) \n",
    "    print('month '+str(month_idx)+\" saved to \" +path_out+ 'erai_'+str(month_idx).zfill(2)+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b796a0-6d31-49cc-b9cd-31e3db73f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nprocs=4  # maybe 12 is a bit much but 2-4 might work? Look at mem usage for serial...\n",
    "\n",
    "## Call in parallel :\n",
    "with mp.Pool(processes = Nprocs) as p:\n",
    "    p.map( month_func, range(1,13) )          # for month_idx in range(1,13):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a73f2b-8522-41dc-a780-cfad36774496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0374828-7c32-438a-a476-0df70c732f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac77cd-1f7f-422a-9275-43e0920f5105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c088b2-1501-44c5-a7ce-aed18f35d218",
   "metadata": {},
   "source": [
    "            # Original code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442781a-a776-4887-ad45-9638eacd9543",
   "metadata": {},
   "source": [
    "## Calculate water vapor mixing ratio, air temperature, and convective precipitation (units)\n",
    "\n",
    "Original code from RYan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7090f-9463-4ed6-970c-2bd2c4f0789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_bnds, lon_bnds = [25, 56], [-130, -96] # W-Conus\n",
    "\n",
    "# Crop to Great Lakes domain (+0.5 deg)\n",
    "buff=0.5\n",
    "lat_bnds = [ GEO.XLONG_M.values.min()-buff, GEO.XLONG_M.values.max()+buff]\n",
    "lon_bnds = [ GEO.XLAT_M.values.min()-buff, GEO.XLAT_M.values.max() +buff] \n",
    "print(lat_bnds, lon_bnds)\n",
    "\n",
    "years=np.arange(1979,2020,1)\n",
    "months=np.arange(1,13,1)\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "    \n",
    "        try:\n",
    "            files=sorted(glob.glob(path_in+'/erai-'+str(year).zfill(2)+'-'+str(month).zfill(2)+'*'))\n",
    "            # print(files)\n",
    "            dsERAi=xr.open_mfdataset(files,combine='by_coords') \n",
    "\n",
    "            # crop to desired domain (gives error?)\n",
    "            # dsERAi_clip=dsERAi.sel(lat=slice(*lat_bnds),lon=slice(*lon_bnds)) # gives error?\n",
    "            # dsERAi_clip=dsERAi.sel(lat=slice(lat_bnds),lon=slice(lon_bnds)) # gives error?\n",
    "            dsERAi_clip=dsERAi\n",
    "\n",
    "            dsERAi_clip['qv']=(dsERAi_clip['qv']/(1-dsERAi_clip['qv']))\n",
    "            dsERAi_clip['qv']=dsERAi_clip['qv'].assign_attrs({'long_name': 'Water Vapor Mixing Ratio', 'units': 'kg kg**-1'})\n",
    "\n",
    "            dsERAi_clip['T'] = dsERAi_clip['theta']*((dsERAi_clip['p']/100000)**(2/7))\n",
    "            dsERAi_clip['T']=dsERAi_clip['T'].assign_attrs({'long_name': 'Air Temperature', 'units': 'K'})\n",
    "\n",
    "            dsERAi_clip['cp']=dsERAi_clip['cp']/21600\n",
    "            dsERAi_clip['cp']=dsERAi_clip['cp'].assign_attrs({'long_name': 'Convective Precipitation', 'units': 'mm/s','Note':'Converted from mm/time step (6 hours) to mm/s by dividing by 21600'})\n",
    "\n",
    "            dsERAi_clip.to_netcdf(path_out+'erai-'+str(year).zfill(2)+'-'+str(month).zfill(2)+'.nc', engine='netcdf4')\n",
    "            print('finished: '+str(year).zfill(2)+'-'+str(month).zfill(2))\n",
    "\n",
    "        except:\n",
    "            print('skipping: '+str(year).zfill(2)+'-'+str(month).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67bdd8-1d82-4e42-b487-de4d267abc1a",
   "metadata": {},
   "source": [
    "## add 15 days before/after:\n",
    "(org code from Ryan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b077c-5cab-438e-9948-000dc016318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for month in range(1,13):\n",
    "\n",
    "        month_idx=month\n",
    "        month_grouped=ds['time'].dt.month\n",
    "        month_grouped[month_grouped!=month_idx]=0\n",
    "        idx=np.where(np.diff(month_grouped.values)!=0)[0]\n",
    "        for i in range(len(idx)):\n",
    "            month_grouped[idx[i]-(15*4)+1:idx[i]+1]=month_idx*np.ones(15*4) # previous time steps\n",
    "            if i==0 and month_idx==1:\n",
    "                month_grouped[idx[i]+1:idx[i]+(15*4)+1]=month_idx*np.ones(15*4) # forward time step\n",
    "            elif i == len(idx)-1 and month_idx==12:\n",
    "                print('executed')\n",
    "                month_grouped=month_grouped # leave as is: dont go forward\n",
    "            elif i < len(idx)-1:\n",
    "#                 try:\n",
    "#                     month_grouped[idx[i+1]+1:idx[i+1]+16]=month_idx*np.ones(15)\n",
    "#                 except:\n",
    "#                     month_grouped=month_grouped                  \n",
    "                month_grouped[idx[i+1]+1:idx[i+1]+(15*4)+1]=month_idx*np.ones(15*4)\n",
    "\n",
    "        dsGroup=ds.groupby(month_grouped).groups\n",
    "        ds_month=ds.isel(time=dsGroup[month_idx])\n",
    "        ds_month.to_netcdf(directory+modLs[z]+'_'+str(month_idx).zfill(2)+'.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy39",
   "language": "python",
   "name": "mypy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
